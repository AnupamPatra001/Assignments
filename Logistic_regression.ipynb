{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1: What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?**  \n",
        "Logistic Regression is a type of machine learning algorithm that we use when the outcome we want to predict has only two possibilities — for example, whether an email is spam or not, whether a person will buy a product or not, or whether a student will pass or fail.\n",
        "\n",
        "Even though the name has the word “regression,” it is actually used for classification, not for predicting continuous values.\n",
        "\n",
        "How it works\n",
        "\n",
        "Logistic regression studies the relationship between the input variables (such as age, income, or study hours) and the output variable (like pass or fail).\n",
        "However, instead of giving a direct number as a result, it predicts a probability — a value between 0 and 1.\n",
        "\n",
        "If the probability is closer to 1, the model predicts “yes.”\n",
        "If it is closer to 0, the model predicts “no.”\n",
        "\n",
        "To keep the output within this 0 to 1 range, logistic regression uses a mathematical function called the sigmoid function, which bends a straight line into an S-shaped curve.\n",
        "\n",
        "How it differs from Linear Regression\n",
        "\n",
        "Linear Regression is used when we want to predict continuous values — for example, predicting a person’s height based on their age, or predicting the price of a house.\n",
        "It can output any number, positive or negative.\n",
        "\n",
        "Logistic Regression, on the other hand, is used when we want to predict categories — like whether something will happen or not.\n",
        "It does not give exact numbers but rather the probability that something belongs to a particular class.\n",
        "\n",
        "**Question 2: Explain the role of the Sigmoid function in Logistic Regression.**\n",
        "\n",
        "The Sigmoid function is the heart of logistic regression. Its main job is to take any number the model produces and turn it into something that looks like a probability — a value between 0 and 1.\n",
        "\n",
        "Why we need it\n",
        "\n",
        "When a logistic regression model makes a prediction, it first calculates a value using a simple linear equation — something like\n",
        "b0+b1x1+b2x2\n",
        ".\n",
        "This number can be anything: very small, very large, positive, or negative.\n",
        "But we cannot use that directly because probabilities can never be less than 0 or greater than 1.\n",
        "\n",
        "That's where the Sigmoid function helps. It takes this raw number and compresses it into a range between 0 and 1.\n",
        "\n",
        "How it works\n",
        "\n",
        "The Sigmoid function has an S-shaped curve.\n",
        "\n",
        "When the input is a large positive number, the output of the function is close to 1.\n",
        "\n",
        "When the input is a large negative number, the output is close to 0.\n",
        "\n",
        "When the input is around 0, the output is about 0.5.\n",
        "\n",
        "So, the function naturally fits the idea of probability.\n",
        "\n",
        "In logistic regression\n",
        "\n",
        "After calculating the linear part, the model passes the result through the Sigmoid function.\n",
        "The output we get is the probability that the given input belongs to a particular class.\n",
        "\n",
        "Usually, we set a cutoff point at 0.5:\n",
        "\n",
        "If the probability is greater than 0.5, we predict the class as “1” or “Yes.”\n",
        "\n",
        "If it is less than 0.5, we predict the class as “0” or “No.”\n",
        "\n",
        "Example\n",
        "\n",
        "Imagine a model that predicts whether a student will pass an exam based on how many hours they study.\n",
        "The raw output might be something like 2.4, which doesn't mean much on its own.\n",
        "When we apply the Sigmoid function to this value, it converts it to 0.92 — meaning there is a 92% chance the student will pass.\n",
        "\n",
        "**Question 3: What is Regularization in Logistic Regression and why is it needed?**\n",
        "\n",
        "Understanding the need for it\n",
        "\n",
        "When we train a logistic regression model, it tries to find the best coefficients (weights) for each input variable so that it can make accurate predictions.\n",
        "Sometimes, especially when the data has many features or noise, the model starts fitting too closely to the training data. It tries to capture every small detail, even random fluctuations that don’t actually represent real patterns.\n",
        "\n",
        "As a result, the model learns the training data too well but fails to generalize — this is called overfitting.\n",
        "Regularization helps solve this problem.\n",
        "\n",
        "How it works\n",
        "\n",
        "Regularization adds a penalty term to the model’s cost function.\n",
        "This penalty discourages the model from assigning very large values to the coefficients.\n",
        "When the coefficients are smaller, the model becomes simpler and more general, which improves its ability to perform well on new data.\n",
        "\n",
        "There are mainly two types of regularization used in logistic regression:\n",
        "\n",
        "L1 Regularization (Lasso)\n",
        "\n",
        "It adds the absolute value of the coefficients as a penalty.\n",
        "\n",
        "This can shrink some coefficients to exactly zero, effectively removing less important features from the model.\n",
        "\n",
        "L2 Regularization (Ridge)\n",
        "\n",
        "It adds the square of the coefficients as a penalty.\n",
        "\n",
        "This makes the coefficients smaller but rarely zero.\n",
        "\n",
        "It helps reduce the influence of less important features without completely removing them.\n",
        "\n",
        "Why it is needed\n",
        "\n",
        "To avoid overfitting and make the model generalize better.\n",
        "\n",
        "To handle multicollinearity, where features are highly correlated with each other.\n",
        "\n",
        "To simplify the model by reducing unnecessary complexity.\n",
        "\n",
        "To improve prediction accuracy on new, unseen data.\n",
        "\n",
        "**Question 4: What are some common evaluation metrics for classification models, and why are they important?**\n",
        "\n",
        "When we build a classification model, like logistic regression, we need to check how well it actually performs.\n",
        "Just because a model gives some predictions doesn’t mean they’re always reliable — so we use evaluation metrics to measure its performance.\n",
        "These metrics help us understand where the model is doing well and where it’s making mistakes.\n",
        "\n",
        "1. Accuracy\n",
        "\n",
        "Accuracy tells us how many predictions the model got right overall.\n",
        "If out of 100 test cases the model correctly predicts 90, then its accuracy is 90%.\n",
        "\n",
        "Accuracy is simple and useful when the data is balanced (when both classes have roughly the same number of examples).\n",
        "But if one class dominates — say 95% “no” and 5% “yes” — the model could just keep predicting “no” and still get 95% accuracy.\n",
        "That’s why accuracy alone isn’t always enough.\n",
        "\n",
        "2. Precision\n",
        "\n",
        "Precision answers the question: When the model predicted something as positive, how often was it correct?\n",
        "\n",
        "For example, if a spam detector says 10 emails are spam and 8 actually are, the precision is 8 out of 10.\n",
        "So precision focuses on how trustworthy the positive predictions are.\n",
        "It’s especially important in situations where false positives are costly — like marking an important email as spam or diagnosing someone as sick when they’re not.\n",
        "\n",
        "3. Recall (or Sensitivity)\n",
        "\n",
        "Recall tells us how well the model finds all the actual positives.\n",
        "\n",
        "For example, if there are 10 spam emails and the model correctly finds 8 of them, the recall is 8 out of 10.\n",
        "Recall matters most when missing a positive case is serious — like failing to detect a disease or missing a fraudulent transaction.\n",
        "\n",
        "4. F1 Score\n",
        "\n",
        "Sometimes we want a balance between precision and recall.\n",
        "The F1 Score does exactly that — it combines the two into one number.\n",
        "If both precision and recall are high, the F1 score will also be high.\n",
        "It’s useful when the dataset is uneven or when we care equally about false positives and false negatives.\n",
        "\n",
        "5. Confusion Matrix\n",
        "\n",
        "A confusion matrix is a simple table that shows where the model got things right and where it went wrong.\n",
        "It breaks predictions into four parts:\n",
        "\n",
        "True Positives (correctly predicted “yes”)\n",
        "\n",
        "True Negatives (correctly predicted “no”)\n",
        "\n",
        "False Positives (predicted “yes” but actually “no”)\n",
        "\n",
        "False Negatives (predicted “no” but actually “yes”)\n",
        "\n",
        "Looking at this table helps us understand the types of mistakes the model makes.\n",
        "\n",
        "6. ROC Curve and AUC\n",
        "\n",
        "The ROC curve shows how well the model separates the two classes at different decision thresholds.\n",
        "The AUC (Area Under the Curve) gives a single score — the higher it is (closer to 1), the better the model is at distinguishing between classes.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E9DJBWAWStJf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo728u3fSjHr",
        "outputId": "1e563faf-1220-4691-ea7b-cef19465a11b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted values: [1 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0]\n",
            "Actual values: [1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0]\n",
            "Model Accuracy: 100.0 %\n"
          ]
        }
      ],
      "source": [
        "# Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame, splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.(Use Dataset from sklearn package)(Include your Python code and output in the code box below.)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from sklearn\n",
        "iris = datasets.load_iris()\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# Save dataset to CSV\n",
        "df.to_csv(\"iris.csv\", index=False)\n",
        "\n",
        "# Load CSV into DataFrame\n",
        "data = pd.read_csv(\"iris.csv\")\n",
        "\n",
        "# Keep only two classes for binary classification\n",
        "data = data[data['target'] != 2]\n",
        "\n",
        "X = data[iris.feature_names]\n",
        "y = data['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Predicted values:\", y_pred)\n",
        "print(\"Actual values:\", list(y_test))\n",
        "print(\"Model Accuracy:\", round(accuracy * 100, 2), \"%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 6: Write a Python program to train a Logistic Regression model using L2\n",
        "# regularization (Ridge) and print the model coefficients and accuracy.\n",
        "# (Use Dataset from sklearn package)\n",
        "# (Include your Python code and output in the code box below.)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "df = df[df['target'] != 2]\n",
        "\n",
        "X = df[iris.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Model Coefficients:\", model.coef_)\n",
        "print(\"Model Accuracy:\", round(accuracy * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwW_eP_nW6x4",
        "outputId": "39f9ab22-cf24-41fb-e7ac-bc321d48ebe5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients: [[-0.3753915  -1.39664105  2.15250857  0.96423532]]\n",
            "Model Accuracy: 100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 7: Write a Python program to train a Logistic Regression model for multiclass\n",
        "# classification using multi_class='ovr' and print the classification report.\n",
        "# (Use Dataset from sklearn package)\n",
        "# (Include your Python code and output in the code box below.)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "X = df[iris.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoCGx7u2XRo8",
        "outputId": "b66e23df-bdcc-494b-8901-065cc36a3127"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 8: Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "# hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "# accuracy.\n",
        "# (Use Dataset from sklearn package)\n",
        "# (Include your Python code and output in the code box below.)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "X = df[iris.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Validation Accuracy:\", round(accuracy * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUVvOBeEXdbr",
        "outputId": "9ba52c19-449c-45d7-c876-b7407c1fd47f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Validation Accuracy: 100.0 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 9: Write a Python program to standardize the features before training Logistic\n",
        "# Regression and compare the model's accuracy with and without scaling.\n",
        "# (Use Dataset from sklearn package)\n",
        "# (Include your Python code and output in the code box below.)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "X = df[iris.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression without scaling\n",
        "model1 = LogisticRegression(max_iter=200)\n",
        "model1.fit(X_train, y_train)\n",
        "y_pred1 = model1.predict(X_test)\n",
        "accuracy_without_scaling = accuracy_score(y_test, y_pred1)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Logistic Regression with scaling\n",
        "model2 = LogisticRegression(max_iter=200)\n",
        "model2.fit(X_train_scaled, y_train)\n",
        "y_pred2 = model2.predict(X_test_scaled)\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred2)\n",
        "\n",
        "print(\"Accuracy without scaling:\", round(accuracy_without_scaling * 100, 2), \"%\")\n",
        "print(\"Accuracy with scaling:\", round(accuracy_with_scaling * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okBe1accXu1C",
        "outputId": "4b68e1e0-5651-4416-84fd-0971655f52af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 100.0 %\n",
            "Accuracy with scaling: 100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10: Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.**\n",
        "\n",
        "1. Understand the data and problem\n",
        "\n",
        " - You have an imbalanced dataset where only 5% of customers respond to a marketing campaign.\n",
        " - This is a binary classification problem: Responded (Yes/No).\n",
        " - Since the classes are highly imbalanced, a simple logistic regression trained on raw data may always predict “No” and still appear 95% accurate. So careful handling is needed.\n",
        "\n",
        "2. Data preprocessing\n",
        "\n",
        " - Check for missing values and handle them (impute or remove).\n",
        "\n",
        " - Convert categorical features to numerical using one-hot encoding or label encoding.\n",
        "\n",
        " - Feature scaling: Use StandardScaler to standardize features so that all numeric features contribute equally to the model. This is especially important if features vary widely in scale (e.g., income vs. number of purchases).\n",
        "\n",
        "3. Handle class imbalance\n",
        "\n",
        " - Since only 5% of customers respond:\n",
        "\n",
        " - Use resampling techniques:\n",
        "\n",
        " - Oversampling the minority class using SMOTE (Synthetic Minority Oversampling Technique).\n",
        "\n",
        " - Undersampling the majority class (if dataset is very large).\n",
        "\n",
        " - Alternatively, use class weights in logistic regression: class_weight='balanced'. This tells the model to pay more attention to the minority class without changing the dataset.\n",
        "\n",
        "4. Train/Test split\n",
        "\n",
        " - Split the data into training and test sets.\n",
        "\n",
        " - Keep the test set untouched, preferably stratified so that the class distribution is preserved.\n",
        "\n",
        " - Training set can then be balanced using the techniques above.\n",
        "\n",
        "5. Model training with logistic regression\n",
        "\n",
        " - Use L2 regularization (ridge) to prevent overfitting.\n",
        "\n",
        " - Set class_weight='balanced' to account for imbalance.\n",
        "\n",
        " - Train the logistic regression on the scaled and balanced data.\n",
        "\n",
        "6. Hyperparameter tuning\n",
        "\n",
        " - Use GridSearchCV or RandomizedSearchCV to tune important parameters:\n",
        "\n",
        " - C (regularization strength)\n",
        "\n",
        " - penalty (L1 or L2)\n",
        "\n",
        " - solver appropriate for your penalty and dataset size\n",
        "\n",
        " - Use cross-validation with stratified folds to maintain class distribution.\n",
        "\n",
        "7. Model evaluation\n",
        "\n",
        " - Accuracy is misleading for imbalanced data — a 95% accuracy may just reflect the majority class.\n",
        "\n",
        " - Use metrics that focus on minority class performance:\n",
        "\n",
        " - Precision: Of all customers predicted to respond, how many actually responded?\n",
        "\n",
        " - Recall (Sensitivity): Of all customers who responded, how many did the model identify?\n",
        "\n",
        " - F1 Score: Balance between precision and recall.\n",
        "\n",
        " - ROC-AUC: Measures the model’s ability to distinguish responders from non-responders.\n",
        "\n",
        " - Confusion matrix: To visualize true positives, false positives, true negatives, and false negatives.\n",
        "\n",
        "8. Final deployment considerations\n",
        "\n",
        " - Test the model on new data to ensure it generalizes.\n",
        "\n",
        " - Use the predicted probabilities (not just the 0/1 class) to rank customers for marketing campaigns.\n",
        "\n",
        " - Continuously monitor model performance as customer behavior changes over time.\n"
      ],
      "metadata": {
        "id": "fZZCTKasYHRx"
      }
    }
  ]
}